{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232c88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If file not downloaded\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "with zipfile.ZipFile(\"archive.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f1c010",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\leezh\\\\Downloads\\\\theatre'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m current \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m     29\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtheatre\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(current\u001b[38;5;241m+\u001b[39mfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(current):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\leezh\\\\Downloads\\\\theatre'"
     ]
    }
   ],
   "source": [
    "# create folder\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "timenow = datetime.now().strftime('%x,%X')\n",
    "\n",
    "class extract:\n",
    "    def __init__(self, input):\n",
    "        data = input.split(',')\n",
    "        self.date = data[0].split('/')\n",
    "        self.time = data[1].split(':')\n",
    "    def day(self):\n",
    "        return int(self.date[1])\n",
    "    def month(self):\n",
    "        return int(self.date[0])\n",
    "    def year(self):\n",
    "        return int(self.date[2])\n",
    "    def hour(self):\n",
    "        return int(self.time[0])\n",
    "    def minute(self):\n",
    "        return int(self.time[1])\n",
    "    def second(self):\n",
    "        return int(self.time[2])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "current = os.getcwd()\n",
    "folder = \"\\\\theatre\"\n",
    "os.mkdir(current+folder)\n",
    "if os.path.getsize(current+folder) == 0:\n",
    "    for filename in os.listdir(current):\n",
    "        f = os.path.join(current, filename)\n",
    "#         print(f)\n",
    "#         print(current+folder)\n",
    "        modtime = time.strftime('%x,%X', time.localtime(os.path.getmtime(f)))\n",
    "        filetime = extract(modtime)\n",
    "        nowtime = extract(timenow)\n",
    "        if filetime.year() == nowtime.year() and filetime.month() == nowtime.month() and filetime.day() == nowtime.day():\n",
    "#             print(f,current+folder)\n",
    "#             print(filetime.day(),nowtime.day())\n",
    "#             print(filetime.month(),nowtime.month())\n",
    "#             print(filetime.year(),nowtime.year())\n",
    "            if f != current+folder:\n",
    "                os.rename(current+'\\\\'+filename, current+folder+'\\\\'+filename)\n",
    "os.chdir(current+folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da20426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5944a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 2514s 10s/step - loss: 2.4587 - accuracy: 0.2955 - val_loss: 2.1445 - val_accuracy: 0.3469\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 2063s 8s/step - loss: 1.8667 - accuracy: 0.4205 - val_loss: 2.2824 - val_accuracy: 0.3250\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 2197s 9s/step - loss: 1.5049 - accuracy: 0.5251 - val_loss: 2.2654 - val_accuracy: 0.3210\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 2264s 9s/step - loss: 1.1279 - accuracy: 0.6545 - val_loss: 2.4484 - val_accuracy: 0.3052\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 2419s 10s/step - loss: 0.7531 - accuracy: 0.7883 - val_loss: 2.6513 - val_accuracy: 0.3128\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 2542s 10s/step - loss: 0.4814 - accuracy: 0.8752 - val_loss: 2.8756 - val_accuracy: 0.3087\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 2336s 10s/step - loss: 0.2921 - accuracy: 0.9410 - val_loss: 3.1130 - val_accuracy: 0.2945\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 2223s 9s/step - loss: 0.1580 - accuracy: 0.9809 - val_loss: 3.2634 - val_accuracy: 0.2970\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 2187s 9s/step - loss: 0.0852 - accuracy: 0.9955 - val_loss: 3.4154 - val_accuracy: 0.3021\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 2347s 10s/step - loss: 0.0521 - accuracy: 0.9989 - val_loss: 3.5856 - val_accuracy: 0.2792\n",
      "62/62 [==============================] - 500s 8s/step - loss: 3.5856 - accuracy: 0.2792\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = 0\n",
    "for i in os.listdir(os.getcwd()):\n",
    "    num_classes += 1\n",
    "\n",
    "# Specify the path to the 'theatre' folder\n",
    "data_folder = os.getcwd()\n",
    "\n",
    "# Initialize empty lists to store the images and their corresponding labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each genre folder\n",
    "for genre in os.listdir(data_folder):\n",
    "    genre_folder = os.path.join(data_folder, genre)\n",
    "    if os.path.isdir(genre_folder):\n",
    "        # Iterate through each image file in the genre folder\n",
    "        for filename in os.listdir(genre_folder):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                # Load the image using OpenCV\n",
    "                image = cv2.imread(os.path.join(genre_folder, filename))\n",
    "                # Preprocess the image (e.g., resize, normalize)\n",
    "                image = cv2.resize(image, (224, 224))  # Resize to a fixed size\n",
    "                image = image / 255.0  # Normalize pixel values between 0 and 1\n",
    "                # Append the image and its genre label to the lists\n",
    "                images.append(image)\n",
    "                labels.append(genre)\n",
    "\n",
    "# Convert the image and label lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform label encoding and one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_one_hot = to_categorical(labels_encoded)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # num_classes is the number of movie genres\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38337ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "\n",
    "# Specify the path and filename for saving the model\n",
    "save_path = current+folder+'\\\\model.h5'\n",
    "\n",
    "# Save the model\n",
    "model.save(save_path)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7348e7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leezh\\Downloads\\theatre\\model.h5.zip\n"
     ]
    }
   ],
   "source": [
    "# zip up the model\n",
    "import shutil \n",
    "import os.path\n",
    "\n",
    "# Creating the ZIP file \n",
    "archived = shutil.make_archive(save_path, 'zip', save_path)\n",
    "\n",
    "if os.path.exists(save_path+'.zip'):\n",
    "   print(archived)\n",
    "else: \n",
    "   print(\"ZIP file not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction code\n",
    "# import just in case it did not get imported\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Specify the path to the folder containing the new movie images\n",
    "new_movies_folder = 'path/to/new/movies' # this should be replaced with the actual folder path\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('path/to/saved/model.h5') # this should be replaced with the model path\n",
    "\n",
    "# Initialize an empty list to store the preprocessed movie images\n",
    "preprocessed_images = []\n",
    "\n",
    "# Iterate through each movie file in the folder\n",
    "for filename in os.listdir(new_movies_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Load the movie image using OpenCV\n",
    "        movie_image = cv2.imread(os.path.join(new_movies_folder, filename))\n",
    "        # Preprocess the movie image (e.g., resize, normalize)\n",
    "        preprocessed_image = cv2.resize(movie_image, (224, 224))  # Resize to the same size as training images\n",
    "        preprocessed_image = preprocessed_image / 255.0  # Normalize pixel values between 0 and 1\n",
    "        # Append the preprocessed image to the list\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "\n",
    "# Convert the list of preprocessed images to a NumPy array\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "\n",
    "# Make predictions on the new movie images\n",
    "predictions = model.predict(preprocessed_images)\n",
    "\n",
    "# Assuming one-hot encoded genre labels\n",
    "# Convert the predictions to genre labels\n",
    "predicted_labels = [label_encoder.inverse_transform([np.argmax(pred)])[0] for pred in predictions]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
